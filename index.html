<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MAGCN : Multi-modal Adaptive Graph Convolutional Network for Disease Diagnosis">
  <meta name="keywords" content="Multi-modality data, Graph convolutional network, Disease diagnosis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MAGCN : Multi-modal Adaptive Graph Convolutional Network for Disease Diagnosis</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src=""></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MAGCN : Multi-modal Adaptive Graph Convolutional Network for Disease Diagnosis</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Xinyue Li</a><sup>1</sup>,</span>
<!--             <span class="author-block">
              <a href="https://sjtuplayer.github.io/">Teng Hu</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://zhangzjn.github.io/">Jiangning Zhang</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://yiranran.github.io/">Ran Yi</a><sup>1#</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/YuzhenD">Yuzhen Du</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=1621dVIAAAAJ">Xu Chen</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://orcid.org/0000-0001-7910-810X/">Liang Liu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://orcid.org/0000-0002-6592-8411/">Yabiao Wang</a><sup>2</sup>
            </span>
            <span class="author-block">
              <a href="https://orcid.org/0000-0003-4216-8090/">Chengjie Wang</a><sup>1,2</sup>
            </span> -->
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Zhejiang University, Hangzhou, China</span>
<!--             <span class="author-block"><sup>2</sup>Youtu Lab, Tencent, Shanghai, China </span> -->
          </div>
<!--           <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University, Shanghai, China</span>
            <span class="author-block"><sup>2</sup>Youtu Lab, Tencent, Shanghai, China </span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--              <span class="link-block">-->
<!--                <a href=""-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                  </a>-->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            图神经网络（GNN）因其强大的表征能力在多模态疾病诊断任务中取得了优异的性能。图的构建决定了信息如何聚合和传播，在图学习中起着至关重要的作用。而现有方法往往忽略模态间的互补信息，专注于捕捉模态共享信息而引入错误的相关性信息。MAGCN 方法从潜在表示和原始数据构建自适应图并进行加权求和，使二者相互补充。对于图中包含噪声的连接，应用 kNN 稀疏技术进行去除。在两种疾病预测任务上的实验表明，所提出的 MAGCN 取得了良好的性能。
          </p>
        </div>
      </div>
    </div>
    </div>
    <!--/ Abstract. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">引言</h2>
        <div class="content has-text-justified">
          <p>
            <br>
            与单一模态的数据相比，多模态数据提供的互补信息使疾病诊断更加可靠。近年来，多核学习、非负矩阵分解和深度神经网络等方法被用来学习多模态共享表示或融合多模态特征以获得更好的疾病诊断效果，而单一模态的特异性补充信息和患者关系往往未得到充分利用。而图神经网络模型（GNN)为信息集成和关系发现提供了一种有效的方式，大多方法通过预定义的相似性度量构建患者关系图，接着应用 GCN 聚合局部邻域上的患者特征以给出预测结果。基于单图的方法通过图构建和 GNN 将成像和非成像模态结合起来，而无法有效地挖掘每种模态的内在信息。基于多图的方法根据每种模态并行构建多个图，然后集成从不同图学习到的嵌入以进行预测。基于图的方法在疾病诊断和预测任务中取得了优异的性能，但仍需进一步考虑两个关键问题：<br>
            <b>1.不充分的患者表征信息</b><br>
            常用的直接连接法和模态内注意力机制都难以捕获模态间相关性，学习到表征信息可能偏向于单一模态。大多方法注重于捕捉共性信息，而忽略了模态之间的差异，导致缺乏特异性的互补信息。且往往通过潜在的多模态表示来构建图表，会忽略原始的信息特征，导致图中错误的关联。<br>
            <b>2.采用手工方式进行图构建</b><br>
            现有的基于单图和多图的方法通常通过手工设计的相似性度量来构建图，很难推广到下游任务。而生物医学领域的图结构学习相关研究较少。<br><br>
            主要贡献有如下几个方面：<br>
            1. 我们提出了一种用于多模态自适应图卷积模型（MAGCN），用于阿尔兹海默症和自闭症的诊断任务。<br>
            2. 为充分表征多模态患者，在通过注意力机制获取特异性模态表示的基础上，引入自适应权重学习的原始数据，使其与嵌入特征相互补充。<br>
            3. 针对图卷积后的过度平滑问题，引入knn方法去除患者图中的错误连接。<br>
            4. 新颖的损失函数和训练策略使模型以端到端的方式联合优化，与SOTA方法比较， MAGCN 在疾病诊断任务上展现出了显著的优势。<br>
          </p>
          </div>
          <br/>
</section>
  
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">相关工作</h2>
        <div class="content has-text-justified">
          <h3 class="title is-4">多模态融合</h3>
          <p>
            <br>
早期的研究工作主要将不同模态的原始数据或特征表示直接串联输入到分类器中，Jesneck等人通过为每个模态训练单独的分类器并合并其输出以做出最终决策。这些方法可能无法有效处理多模态异构数据，导致维度灾难。Liu等人采用多核学习将数据映射到高维嵌入中，接着加权组合这些嵌入输入SVM进行分类。近年来，随着深度神经网络的飞速发展，其在多模态数据融合方面也得到了广泛应用。Pan等人引入了选择策略来选择高度相关的多模态特征以降低特征维度，并利用多注意力融合模块将数据相结合生成诊断结果。然而，这些方法往往忽视了模态间的相关性以及模态特定信息的复杂性。深度半非负矩阵分解方法可以有效学习模态共享表示，而Ning等人提出的原始特征与共享嵌入之间的双向映射可以进一步挖掘原始模态相关性。然而，在多模态数据中挖掘互补信息仍然是疾病诊断的关键问题。在此背景下，Zheng等人提出了模态感知表示的方法，同时获取共享信息和特异信息。现有大多数研究方法集中于融合多模态表示，而患者之间的相似性相对未被充分探索。因此，需要能够有效整合多模态信息，同时利用患者相似性来增强疾病诊断的方法。
          </p>
          </div>
          <br/>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">方法</h2>
        <div class="content has-text-justified">
          <p>
            <br>
          1.多模态表示提取<br>
            对于输入X，使用编码器提取模态特征，采用缩放点积注意力机制获取模态共享和特异表示。<br>
          2.图结构学习<br>
            加权求和从原始数据和潜在嵌入中的两个图，采用kNN稀疏化去除错误连接。<br>
          3.GCN分类<br>
            利用GCN聚合邻居结点信息进行预测，结合辅助分类器损失进行联合优化。<br>
          </p>
          <div class="columns is-centered">
            <img src="./static/images/p1.png" class="interpolation-image" alt="Interpolate start reference image.">
          </div>
         </div>
          <br/>
  </section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">数据集及预处理</h2>
        <div class="content has-text-justified">
          <p>
            实验评估了 MAGCN 在两个广泛使用的多模态生物医学数据集（TADPOLE 数据集和 ABIDE 数据集）上的性能. 
          </p>
          <h3 class="title is-4">
            <a href="https://tadpole.grand-challenge.org/Data/" target="_blank">TADPOLE</a>
          </h3>
          <p>
            TADPOLE 作为阿尔茨海默病神经影像倡议（Alzheimer’s Disease Neuroimaging Initiative, ADNI）数据库的子集，TADPOLE数据集包含从六种模态中提取的特征，包括反映脑萎缩程度的磁共振成像（MRI）、检测异常分子的正电子发射断层扫描（PET）、认知测试、脑脊液（CSF）生物标志物、风险因素和人口统计信息. 对于阿尔茨海默病诊断任务，我们从 TADPOLE 数据集中选择了 598 名具有多模态特征的受试者，分别为 209 名正常对照（NC）、315 名轻度认知障碍（MCI）患者和 74 名阿尔茨海默病（AD） 患者. 由于每个患者可能有多个医疗记录，根据受试者 ID 仅保留单个样本并对每种模态进行特征选择. 特征缺失率大于5%的受试者被剔除，剩余样本采用均值插补法进行缺失值填充. 
          </p>
          <h3 class="title is-4">
            <a href="https://fcon_1000.projects.nitrc.org/indi/abide/" target="_blank">ABIDE</a>
          </h3>
            <p>
              ABIDE 为了加速对自闭症神经基础的理解，自闭症脑成像数据交换（ABIDE）收集了来自 24 个不同实验室的功能和结构脑成像数据. 数据包含四种模态：人口统计信息、自动解剖质量评估指标、自动功能质量评估指标和功能磁共振成像连接网络. 实验中选择 871 名受试者进行自闭症疾病诊断，包括403个自闭症谱系障碍（ASD）受试者和468个正常对照（NC）.实验使用连接组分析的可配置管道（C-PAC）进行数据预处理. 
            </p>
          </div>
          <br/>


    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">实验结果与分析</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4">对比实验</h3>
        <div class="content has-text-justified">
          <p>
            <b>基线方法: </b><br><br>
            PopGCN: 利用人口统计信息手动构建图，并通过图卷积网络 (GCN) 聚合受试者的成像特征进行分类。<br>
            InceptionGCN: 引入多尺寸图滤波器，以提升GCN在疾病诊断任务中的表现。<br>
            Multi-GCN: 采用自注意力机制聚合从每个统计元素构建的多个图所得的分类预测值。<br>
            EV-GCN: 引入具有动态边权重的自适应可学习图，由非成像特征计算得出权重，随后采用谱GCN优化。<br>
            LGL: 不同于手工设计图的方法，基于融合多模态嵌入相似性构建图结构，并通过GCN进行分类。<br>
            MMGL: 利用模态感知表示学习提取模态特异性表示和模态共享表示，并通过自适应图神经网络捕捉患者之间的联系。<br>
            <br>实验将 MAGCN 方法与以上基线方法进行了比较。实验结果表明，方法在两个数据集上都优于最佳基线方法。使用融合多模态特征创建的图普遍表现较好， MAGCN 将经过自适应权重学习的原始数据和嵌入特征相结合，在多模态疾病诊断任务中取得了较好的性能。
          </p>
        </div>
        <div class="columns is-centered">
            <img src="./static/images/t1.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div>
        <br/>
          </div>
        </div>

    <h3 class="title is-4">消融实验</h3>
        <div class="content has-text-justified">
          <p>
            从消融实验的评估结果中，可以观察到方法各组成部分的贡献。由自适应权重学习的原始数据和嵌入特征构建的图 S 对最终结果贡献较大，改进的损失函数相比于原论文会产生更好的结果。kNN 稀疏化也有助于优化图结构，去除错误的连接。
          </p>
          <div class="columns is-centered">
            <img src="./static/images/t2.png" class="interpolation-image" alt="Interpolate start reference image.">
            </div>
        <h3 class="title is-4">类内与类间相似度可视化</h3>
        <div class="content has-text-justified">
          <p>
            热图展示了任意两个患者的特征向量之间的余弦相似度，可以观察到 GNN 的效果以及和 MAGCN 相比于 MMGL 的改进。矩阵的对角线区域表示类内相似性，而非对角线部分表示类间相似性。原始多模态嵌入经过GNN模块生成聚合特征，显著增强了类内相似性，减少了类间相似性，这表明图学习显著提高了表示质量，
            MAGCN 方法有效地学习了更具区分性的特征表示，而 MMGL 部分样本具有较高的类间相似性，如矩阵的非对角线区域中的黄色条带所示。
          </p>
          <div class="columns is-centered">
            <img src="./static/images/p2.png" class="interpolation-image" alt="Interpolate start reference image.">
        </div>
  </section>

<!--     <h2 class="title is-3"></h2>
        <div class="content has-text-justified">
          <p>
            We employ the UNet trained on our generated data to compare with
            the state-of-the-art models that are specially designed for anomaly
            detection.
          </p>
          <div class="columns is-centered">
            <img src="./static/images/table5.png" class="interpolation-image" alt="Interpolate start reference image.">
      </div>
          </div>
          <br/>
</section> -->

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{hu2023anomalydiffusion,
  title={AnomalyDiffusion: Few-Shot Anomaly Image Generation with Diffusion Model},
  author={Hu, Teng and Zhang, Jiangning and Yi, Ran and Du, Yuzhen and Chen, Xu and Liu, Liang and Wang, Yabiao and Wang, Chengjie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2024}
}
</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="">
        <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
      </a>
      <a class="icon-link" href="" disabled="">
        <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
<!--           <p>
            We borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> for our website.
            We sincerely appreciate Nerfies authors for their awesome templates.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
